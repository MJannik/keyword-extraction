{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddbb8d81"
      },
      "source": [
        "# A Quantitative Analysis of Unsupervised Keyword Extraction Methods\n",
        "\n",
        "\n",
        "### This code is part of a Bachelor thesis at Humboldt University Berlin. \n",
        "\n",
        "This code will compare commonly used unsupervised keyphrase extraction methods, which are structured in three areas: Statistical methods (TF-IDF, YAKE, RAKE), mathods that are based on graphs (SingleRank, TextRank), and deep learning methods (KeyBERT). The latter uses language-specific pre-trained models, in this case for German, whereas the statistical and graph-based methods need no training and are language unspecific."
      ],
      "id": "ddbb8d81"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc58efad"
      },
      "source": [
        "## Import Packages"
      ],
      "id": "bc58efad"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vdv0LaVHoIcV"
      },
      "source": [
        "This cell connects Google Drive, where the dataset is stored, to Google Colab"
      ],
      "id": "Vdv0LaVHoIcV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oizWoIwjtPKa",
        "outputId": "a856155a-4e87-4efd-96f5-31955d29ff60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "oizWoIwjtPKa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez5eWusrof0X"
      },
      "source": [
        "This call installs all necessary packages and language models"
      ],
      "id": "ez5eWusrof0X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa86WMzBvxLB"
      },
      "outputs": [],
      "source": [
        "!pip3 install scipy\n",
        "#!pip3 install pytextrank\n",
        "!pip3 install git+https://github.com/boudinfl/pke.git\n",
        "!pip3 install python-rake\n",
        "!pip3 install yake\n",
        "!pip3 install sentence_transformers\n",
        "!pip3 install keybert\n",
        "!pip3 install keyphrase_vectorizers\n",
        "!pip3 install flair\n",
        "!pip3 install futures\n",
        "!pip3 install spacy-transformers\n",
        "!pip3 install swifter\n",
        "\n",
        "!python -m spacy download de_dep_news_trf\n",
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download de_core_news_lg"
      ],
      "id": "fa86WMzBvxLB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqfJqdGBUOml"
      },
      "source": [
        "This cell loads the packages"
      ],
      "id": "GqfJqdGBUOml"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0cc877f"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from IPython import display\n",
        "import scipy\n",
        "import sys\n",
        "import spacy\n",
        "\n",
        "import platform\n",
        "import functools\n",
        "from string import printable\n",
        "from statistics import mean\n",
        "from operator import itemgetter\n",
        "from itertools import islice, combinations\n",
        "import glob\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import concurrent.futures\n",
        "import itertools\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from keybert import KeyBERT\n",
        "#import pytextrank\n",
        "import pke\n",
        "from RAKE import Rake, NLTKStopList\n",
        "from yake import KeywordExtractor\n",
        "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
        "from keyphrase_vectorizers import KeyphraseTfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from flair.embeddings import TransformerDocumentEmbeddings\n",
        "import spacy_transformers\n",
        "\n",
        "from string import punctuation\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem.snowball import GermanStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import tqdm as notebook_tqdm\n",
        "from nltk import sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "# Collect the thrown exception\n",
        "exception_texts = []"
      ],
      "id": "e0cc877f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a683cc3c"
      },
      "source": [
        "## Load Data from Excel"
      ],
      "id": "a683cc3c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpysX77coo3Y"
      },
      "source": [
        "This function reads the excel files with all articles per month and concatenates them. It also seperates the keywords by comma and filters out observations with no text or no keywords."
      ],
      "id": "GpysX77coo3Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNf7knJZhUhj"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "  workbooks = [f for f in os.listdir(path) if f.endswith(\".xlsx\")]\n",
        "  print(workbooks)\n",
        "\n",
        "  outputxlsx = pd.DataFrame()\n",
        "\n",
        "  for file in workbooks:\n",
        "    df = pd.concat(pd.read_excel(path + '/' + file, sheet_name = None), ignore_index = True, sort = False)\n",
        "    outputxlsx = outputxlsx.append(df, ignore_index=True)\n",
        "\n",
        "  # Seperate Keywords by comma\n",
        "  outputxlsx['keywords'] = outputxlsx['keywords'].str.split(',')\n",
        "\n",
        "  outputxlsx = outputxlsx[~outputxlsx['keywords'].isnull()]\n",
        "  outputxlsx = outputxlsx[~outputxlsx['text'].isnull()]\n",
        "\n",
        "  return outputxlsx"
      ],
      "id": "yNf7knJZhUhj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JybejyCpYhs"
      },
      "source": [
        "This cell calls the function to concatenate the data and split it into a test-set (20%) and a tune-set (80%). Both datasets are then saved as excel files to be able to restore the same data split."
      ],
      "id": "0JybejyCpYhs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz75cfgE0Gu_"
      },
      "outputs": [],
      "source": [
        "df = load_data('/content/drive/MyDrive/Bachelorarbeit/Colab_data/Datasets_test')\n",
        "tune_df, test_df = train_test_split(df, test_size=0.2)\n",
        "\n",
        "tune_df.to_excel('/content/drive/MyDrive/Bachelorarbeit/Colab_data/final_datasets/tune_df.xlsx')\n",
        "test_df.to_excel('/content/drive/MyDrive/Bachelorarbeit/Colab_data/final_datasets/test_df.xlsx')"
      ],
      "id": "Sz75cfgE0Gu_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJFDXp0fpnR0"
      },
      "source": [
        "This cell loads the data, converts the keyword collumn to list format, removes all keywords that are not in the text and removes observations with less than 2 keywords."
      ],
      "id": "iJFDXp0fpnR0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nO7EICvxo1Hb"
      },
      "outputs": [],
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "# Function to remove keywords of one observation that are not present in the text\n",
        "def remove_keywords_not_in_text(text, keywords):\n",
        "    keywords_in_text = [x for x in keywords if x in text]\n",
        "    return keywords_in_text\n",
        "\n",
        "tune_df = pd.read_excel('/content/drive/MyDrive/Bachelorarbeit/Colab_data/final_datasets/tune_df.xlsx')\n",
        "tune_df['keywords'] = tune_df['keywords'].apply(literal_eval)\n",
        "tune_df['keywords'] = tune_df['keywords'].apply(lambda x: [s.strip() for s in x])\n",
        "tune_df['keywords'] = tune_df.apply(lambda x: remove_keywords_not_in_text(x.text, x.keywords), axis=1)\n",
        "tune_df = tune_df[tune_df['keywords'].map(len) >= 2]\n",
        "tune_df = tune_df.reset_index(drop=True)\n",
        "\n",
        "test_df = pd.read_excel('/content/drive/MyDrive/Bachelorarbeit/Colab_data/final_datasets/test_df.xlsx')\n",
        "test_df['keywords'] = test_df['keywords'].apply(literal_eval)\n",
        "test_df['keywords'] = test_df['keywords'].apply(lambda x: [s.strip() for s in x])\n",
        "test_df['keywords'] = test_df.apply(lambda x: remove_keywords_not_in_text(x.text, x.keywords), axis=1)\n",
        "test_df = test_df[test_df['keywords'].map(len) >= 2]\n",
        "test_df = test_df.reset_index(drop=True)"
      ],
      "id": "nO7EICvxo1Hb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KWTGiYKTGMH"
      },
      "source": [
        "### Stopwords\n",
        "\n",
        "This cell imports a stopword list. The stopwordlist comes from: https://countwordsfree.com/stopwords/german. The cell also imprts the module printable, which is a list of printable characters and adds the german \"Umlaute\" ('öäüÖÄÜß') "
      ],
      "id": "8KWTGiYKTGMH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckcrM6crTE7y"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "f = open('/content/drive/MyDrive/Bachelorarbeit/Colab_data/stop_words_german.json')\n",
        "stopwords_german = json.load(f)\n",
        "\n",
        "# Add german 'Umlaute to prinatble list.'\n",
        "from string import printable\n",
        "printable = printable + 'öäüÖÄÜß'"
      ],
      "id": "ckcrM6crTE7y"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97d674cf"
      },
      "source": [
        "# Models\n",
        "\n",
        "This section defines the functions for the six keyphrase extraction methods: Statistical-methods (TF-IDF, RAKE, YAKE), graph-based (TextRank, SingleRank), deep learning (KeyBERT)."
      ],
      "id": "97d674cf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7uer94izeOx"
      },
      "source": [
        "## Statistical based methods"
      ],
      "id": "h7uer94izeOx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2120897a"
      },
      "source": [
        "### TF-IDF \n",
        "\n",
        "This function represents the TF-IDF method. TF-IDF determines the relative frequency of a term in a specific text in contrast to the inverse frequency of that term's overall occurrence in all texts.\n",
        "\n",
        "The fist function tfidf_matrix() creates the TF-IDF matrix for the whole dataset - a TF-IDF score is being calculated for every word of the dataset. \n",
        "\n",
        "The second function gets the TF-IDF value.\n",
        "\n",
        "**Hyperparameters:**\n",
        "\n",
        "*   **n-gram:** Minimum and maximum number of words per keyphrase (default = (1, 2))\n",
        "\n",
        "**Source:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
      ],
      "id": "2120897a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b39f029"
      },
      "outputs": [],
      "source": [
        "def tfidf_matrix(df, ngram_range):\n",
        "\n",
        "    tfidf_vectorizer = TfidfVectorizer(use_idf = True, stop_words = stopwords_german, ngram_range = ngram_range) \n",
        "    tfidf_vectorizer_vectors = tfidf_vectorizer.fit_transform(df['text'].tolist())\n",
        "    tfidf_vectorizer_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "    return tfidf_vectorizer_vectors, tfidf_vectorizer, tfidf_vectorizer_feature_names \n",
        "\n",
        "def tfidfvectorizer(number_text, tfidf_vectorizer_vectors, tfidf_vectorizer, tfidf_vectorizer_feature_names, top_n = 10):\n",
        "    \n",
        "    # get vector for document\n",
        "    first_vector_tfidfvectorizer = tfidf_vectorizer_vectors[number_text] \n",
        "    # place tf-idf values in a pandas data frame \n",
        "    df = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=tfidf_vectorizer_feature_names, columns=[\"tfidf\"]) \n",
        "    df = df.sort_values(by=[\"tfidf\"],ascending=False)\n",
        "    df = df.reset_index(level=0)\n",
        "    keywords_list = df['index'].to_list()\n",
        "    return keywords_list[:top_n]"
      ],
      "id": "5b39f029"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bfa37fe"
      },
      "source": [
        "### RAKE\n",
        "\n",
        "This function executes the RAKE method. \n",
        "\n",
        "**hyperparameters:**\n",
        "*    **minCharacters:** Minimum characters allowed in a keyword (default = 1)\n",
        "*    **maxWords:** Maximum number of words allowed in a phrase considered as a keyword (default = 5)\n",
        "*    **minFrequency:** Minimum number of occurrences of a keyword in the text to be considered as a keyword (default = 1)\n",
        "\n",
        "**Source:** https://github.com/fabianvf/python-rake\n"
      ],
      "id": "4bfa37fe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21511f05"
      },
      "outputs": [],
      "source": [
        "def rake(text, minCharacters = 1, maxWords = 5, minFrequency = 1, top_n = 10):\n",
        "    \n",
        "    try:\n",
        "        # Clean the text from non-printable characters.\n",
        "        text = ''.join(word for word in text if word in printable)\n",
        "\n",
        "        # Uses the german stopword list.\n",
        "        r = Rake(stopwords_german)\n",
        "        return [keyphrase for (keyphrase, score) in r.run(text, minCharacters, maxWords, minFrequency)[:top_n]]\n",
        "    \n",
        "    except:\n",
        "        exception_texts.append('RAKE ' + str(text))\n",
        "        return ['EXCEPTION']"
      ],
      "id": "21511f05"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee4c74e9"
      },
      "source": [
        "### YAKE\n",
        "\n",
        "This function executes the YAKE method\n",
        "\n",
        "**Hyperparameters:**\n",
        "\n",
        "*   **n: (max_ngram_size)** Maximum number of words per keyword (default = 3)\n",
        "*   **dedupLim:** (deduplication_thresold) Threshold for the value of the similarity measure for deduplication (default = 0.9)\n",
        "*   **deduplication:** Algorithm to measure the similarity of candidate keywords: levs, jaro or seqm (default = seqm)\n",
        "*   **windowsSize:** Distance (in number of tokens) considered when computing co-occurrences of tokens (default = 1)\n",
        "\n",
        "**Source:** https://github.com/LIAAD/yake"
      ],
      "id": "ee4c74e9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22ff29ed"
      },
      "outputs": [],
      "source": [
        "def yake(text, top_n = 10, n = 3, dedupLim = 0.9, dedupFunc = 'seqm', windowsSize = 1):\n",
        "    \n",
        "    try:\n",
        "        # Initialize the keyword extractor object and its parameters.\n",
        "        kw_extractor = KeywordExtractor (\n",
        "            lan = \"de\",\n",
        "            top = top_n,\n",
        "            n = n,\n",
        "            dedupLim = dedupLim,\n",
        "            dedupFunc = dedupFunc,\n",
        "            windowsSize = windowsSize\n",
        "        )\n",
        "        # Return the extracted keywords, in a list.\n",
        "        return [keyword for (keyword, score) in kw_extractor.extract_keywords(text)]\n",
        "    \n",
        "    except:\n",
        "        exception_texts.append('YAKE ' + str(text))\n",
        "        return ['EXCEPTION']"
      ],
      "id": "22ff29ed"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlWYFTj70G9e"
      },
      "source": [
        "## Graph-based methods"
      ],
      "id": "NlWYFTj70G9e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84677cf9"
      },
      "source": [
        "### TextRank\n",
        "\n",
        "This function executes the TextRank method.\n",
        "\n",
        "**Hyperparameter:**\n",
        "\n",
        "*   **window:** Window for connecting two words in the graph (default = 2)\n",
        "*   **pos:** Set of valid pos for words to be considered as a node in the graph (default = {'NOUN’ ’PROPN'  'ADJ'})\n",
        "\n",
        "*   **top_percent:** Percentage of top vertices to keep for phrase generation (default = 0.33)\n",
        "\n",
        "**Source:** https://github.com/boudinfl/pke/blob/master/pke/unsupervised/graph_based/textrank.py "
      ],
      "id": "84677cf9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMWdlLnR0Ye-"
      },
      "outputs": [],
      "source": [
        "def textrank(text, top_percent = 0.33, top_n = 10, pos = {'NOUN', 'PROPN', 'ADJ'}, window = 2):\n",
        "\n",
        "    try:\n",
        "        # Clean the text from non-printable characters.\n",
        "        text = ''.join(word for word in text if word in printable)\n",
        "        # 1. create a TextRank extractor.\n",
        "        extractor_textrank = pke.unsupervised.TextRank()\n",
        "        # 2. load the content of the document.\n",
        "        extractor_textrank.load_document(input=text, language='de', normalization = False)\n",
        "        # 3. build the graph representation of the document and rank the words.\n",
        "        extractor_textrank.candidate_weighting(window = window, pos = pos, top_percent=top_percent)\n",
        "\n",
        "        return [keyphrase for (keyphrase, score) in extractor_textrank.get_n_best(n = top_n)]\n",
        "\n",
        "    except: \n",
        "        exception_texts.append('textrank ' + str(text))\n",
        "        return ['EXCEPTION']"
      ],
      "id": "mMWdlLnR0Ye-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c514bc5d"
      },
      "source": [
        "### SingleRank\n",
        "\n",
        "This function calls the SingeRank method.\n",
        "\n",
        "**Hyperparameters:**\n",
        "\n",
        "*   **window:** Window within the sentence for connecting words in the graph (default = 10)\n",
        "*   **redundancy_removal:** Boolean variable whether redundant keyphrases are filtered out from the n-best list using levenshtein distance (default = True)\n",
        "*   **pos:** Set of valid pos for words to be considered as nodes in the graph (default = 'NOUN’ ’PROPN'  'ADJ')\n",
        "\n",
        "**Source:** \n",
        "*   https://github.com/boudinfl/pke/blob/master/pke/unsupervised/graph_based/singlerank.py\n"
      ],
      "id": "c514bc5d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d01c435a"
      },
      "outputs": [],
      "source": [
        "def singlerank(text, top_n = 10, window=10, pos=None, normalized = False, redundancy_removal = True):\n",
        "\n",
        "    try:\n",
        "        # Clean the text from non-printable characters.\n",
        "        text = ''.join(word for word in text if word in printable)\n",
        "\n",
        "        # Initialize the keyphrase extraction model.\n",
        "        extractor = pke.unsupervised.SingleRank()\n",
        "\n",
        "        # Load the content of the document and preprocess it with spacy.\n",
        "        # Then, select the keyphrase candidates from the document,\n",
        "        # and weight them using a random walk algorithm.\n",
        "        extractor.load_document(input = text, language = 'de', normalization = normalized)\n",
        "        extractor.candidate_selection()\n",
        "        extractor.candidate_weighting(window = window, pos = pos, normalized = normalized)\n",
        "\n",
        "        # Return the n-highest scored candidates.\n",
        "        return [\n",
        "            keyphrase for (keyphrase, score)\n",
        "            in extractor.get_n_best(n = top_n, redundancy_removal = redundancy_removal)\n",
        "        ]\n",
        "    \n",
        "    except:\n",
        "        exception_texts.append('singlerank ' + str(text))\n",
        "        return ['EXCEPTION']"
      ],
      "id": "d01c435a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDeYPvIU0LU6"
      },
      "source": [
        "## Deep learning methods"
      ],
      "id": "SDeYPvIU0LU6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "003b1501"
      },
      "source": [
        "### KeyBERT\n",
        "\n",
        "This part loads all the language models used for the hyperparameter tuning of the KeyBERT method. It also loads the vectorizers.\n",
        "\n",
        "**Source:** \n",
        "\n",
        "language models: \n",
        "*   https://spacy.io/models/de\n",
        "*   https://huggingface.co/bert-base-german-cased\n",
        "*   https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
        "\n",
        "python packages:\n",
        "*   https://github.com/flairNLP/flair\n",
        "*   https://github.com/explosion/spaCy\n",
        "*   https://github.com/TimSchopf/KeyphraseVectorizers\n",
        "\n"
      ],
      "id": "003b1501"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5L0QDosn4ntX"
      },
      "outputs": [],
      "source": [
        "# Load  language models\n",
        "nlp_kw_model_2 = spacy.load(\"de_core_news_sm\", exclude=['tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer'])\n",
        "kw_model_2 = KeyBERT(model=nlp_kw_model_2)\n",
        "\n",
        "nlp_kw_model_5 = spacy.load(\"de_core_news_lg\", exclude=['tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer'])\n",
        "kw_model_5 = KeyBERT(model=nlp_kw_model_5)\n",
        "\n",
        "bert_german = TransformerDocumentEmbeddings('bert-base-german-cased')\n",
        "kw_model_3 = KeyBERT(model=bert_german)\n",
        "\n",
        "nlp_kw_model_6 = SentenceTransformer(\"distiluse-base-multilingual-cased-v2\")\n",
        "kw_model_6 = KeyBERT(model=nlp_kw_model_6)\n",
        "\n",
        "nlp_kw_model_8 = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "kw_model_8 = KeyBERT(model=nlp_kw_model_8)\n",
        "\n",
        "\n",
        "# load vectorizer\n",
        "vectorizer_keybert = KeyphraseCountVectorizer(spacy_pipeline='de_core_news_sm')"
      ],
      "id": "5L0QDosn4ntX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba7e4bPRAY6q"
      },
      "source": [
        "#### KeyBERT multi document extraction\n",
        "\n",
        "This function uses the build in multi-document processing function of KeyBERT. It takes a list of texts as an input and returnes a list of keywords for every text.\n",
        "\n",
        "**Hyperparameters:**\n",
        "\n",
        "*   **keyphrase_ngram_range:** Minimum and maximum number of words per keyphrase (default = (1, 1))\n",
        "*   **min_df:** Minimum frequency of words (default = 1)\n",
        "*   **model:** BERT model (default = all-MiniLM-L6-v2)\n",
        "\n",
        "**Source:** https://github.com/MaartenGr/KeyBERT"
      ],
      "id": "Ba7e4bPRAY6q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoIx2C_Kinpr"
      },
      "outputs": [],
      "source": [
        "def keybert_bulk(df, keyphrase_ngram_range = (1, 2), top_n = 10, min_df = 1, vectorizer = vectorizer_1, model = kw_model_2, stopwords = stopwords_german):\n",
        "\n",
        "    listText_keybert = df['text'].tolist()\n",
        "\n",
        "    keywords_list = model.extract_keywords(\n",
        "            listText_keybert, \n",
        "            keyphrase_ngram_range = keyphrase_ngram_range,\n",
        "            stop_words = stopwords,\n",
        "            top_n = top_n,\n",
        "            min_df = min_df,\n",
        "            vectorizer = vectorizer\n",
        "    )\n",
        "    \n",
        "    keywords_list_clean = [[i[0] for i in liste_item] for liste_item in keywords_list]\n",
        "\n",
        "    df['extracted'] = keywords_list_clean\n",
        "    #df['extracted'] = df['extracted'].str.split(',')\n",
        "\n",
        "    return df\n"
      ],
      "id": "QoIx2C_Kinpr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTxkxf9WARoQ"
      },
      "source": [
        "#### KeyBERT single document extraction\n",
        "\n",
        "This function is used when running KeyBERT in single document mode. It takes one text as an imput and returns keywords.\n",
        "\n",
        "**Hyperparameters:**\n",
        "\n",
        "*   **keyphrase_ngram_range:** Minimum and maximum number of words per keyphrase (default = (1, 1))\n",
        "*   **min_df:** Minimum frequency of words (default = 1)\n",
        "*   **model:** BERT model (default = all-MiniLM-L6-v2)\n",
        "\n",
        "**Source:** https://github.com/MaartenGr/KeyBERT"
      ],
      "id": "gTxkxf9WARoQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "737943fa"
      },
      "outputs": [],
      "source": [
        "def keybert(text, keyphrase_ngram_range = (1, 2), top_n = 10, nr_candidates = 20, measure = 'maxsum', diversity = 0.7, vectorizer = vectorizer_1, model = kw_model_2, stopwords = stopwords_german):\n",
        "\n",
        "    # Returned the extracted keywords based on the specified arguments. \n",
        "    try:\n",
        "        keywords = [\n",
        "            keyphrase for (keyphrase, _) in \n",
        "            model.extract_keywords (\n",
        "                text, \n",
        "                keyphrase_ngram_range = keyphrase_ngram_range,\n",
        "                stop_words = stopwords,\n",
        "                top_n = top_n,\n",
        "                nr_candidates = nr_candidates,\n",
        "                use_maxsum = True if measure == 'maxsum' else False,\n",
        "                use_mmr = True if measure == 'mmr' else False,\n",
        "                diversity = diversity,\n",
        "                vectorizer = vectorizer\n",
        "        )]\n",
        "        return keywords\n",
        "    \n",
        "    except: \n",
        "        exception_texts.append('keybert ' + str(text))\n",
        "        return ['EXCEPTION']"
      ],
      "id": "737943fa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNqgAeZC0FeG"
      },
      "source": [
        ""
      ],
      "id": "HNqgAeZC0FeG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d656dba"
      },
      "source": [
        "# F1 Score\n",
        "\n",
        "This part calculates the F1 score to evaluate the performance of the chosen models. It can calculate either the partial F1 score or an exact match F1 score. For our experiments, the partial match framwork was used.\n",
        "\n",
        "**Source:** https://github.com/NC0DER/KeyphraseExtraction "
      ],
      "id": "7d656dba"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c9d3513"
      },
      "source": [
        "### Partial Percision K\n",
        "\n",
        "Computes the average partial precision at k, between two lists of keywords.\n",
        "The partial precision is defined as the fraction between the number of correctly partially matched tokens, \n",
        "over the total number of extracted (k) tokens.\n",
        "\n",
        "Assigned should always contain the shorter list, while extracted the longest, as to avoid counting partial matches more times than necessary."
      ],
      "id": "4c9d3513"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e1e39a9"
      },
      "outputs": [],
      "source": [
        "def partial_precision_k(assigned, extracted, k):\n",
        "\n",
        "    assigned, extracted = min((assigned, extracted[:k]), key = len), max((assigned, extracted[:k]), key = len)\n",
        "    assigned_sets = [set(keyword.split()) for keyword in assigned]\n",
        "    extracted_sets = [set(keyword.split()) for keyword in extracted]\n",
        "\n",
        "    return sum(\n",
        "        1.0 for i in assigned_sets  \n",
        "            if any(True for j in extracted_sets if i & j)) / k"
      ],
      "id": "7e1e39a9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df8ae780"
      },
      "source": [
        "### Partial Recall K\n",
        "\n",
        "Computes the average partial recall at k, between two lists of keywords.\n",
        "The partial recall is defined as the fraction between the number of correctly partially matched tokens, over the total number of extracted (k) tokens."
      ],
      "id": "df8ae780"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "739b8e2c"
      },
      "outputs": [],
      "source": [
        "def partial_recall_k(assigned, extracted, k):\n",
        "\n",
        "    assigned_length = len(assigned)\n",
        "    assigned, extracted = min((assigned, extracted[:k]), key = len), max((assigned, extracted[:k]), key = len)\n",
        "    assigned_sets = [set(keyword.split()) for keyword in assigned]\n",
        "    extracted_sets = [set(keyword.split()) for keyword in extracted]\n",
        "\n",
        "    return sum(\n",
        "        1.0 for i in assigned_sets\n",
        "            if any(True for j in extracted_sets if i & j)) / assigned_length"
      ],
      "id": "739b8e2c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b38b5fdb"
      },
      "source": [
        "### Recall K\n",
        "\n",
        "Computes the exact match recall at k, between two lists of keywords.\n",
        "The average precision is defined as the fraction between the number of correctly matched tokens (the intersection of assigned and extracted sets) over the number of assigned tokens."
      ],
      "id": "b38b5fdb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a765eb76"
      },
      "outputs": [],
      "source": [
        "def recall_k(assigned, extracted, k):\n",
        "    return len(set(assigned) & set(extracted[:k])) / len(assigned)"
      ],
      "id": "a765eb76"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25c164f1"
      },
      "source": [
        "### Precission K\n",
        "\n",
        "Computes the exact match precision at k, between two lists of keywords. \n",
        "The precision is defined as the fraction between the number of correctly matched tokens (the intersection of assigned and extracted sets) over the number of extracted (k) tokens. "
      ],
      "id": "25c164f1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63722dd0"
      },
      "outputs": [],
      "source": [
        "def precision_k(assigned, extracted, k):\n",
        "    return len(set(assigned) & set(extracted[:k])) / k"
      ],
      "id": "63722dd0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1564053"
      },
      "source": [
        "### F1 \n",
        "\n",
        "Computes the f1 measure at k.\n",
        "The f1 measure at k is defined as the harmonic mean of the precision at k and recall at k."
      ],
      "id": "a1564053"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f81ddf65"
      },
      "outputs": [],
      "source": [
        "def f1_measure_k(assigned, extracted, k, partial = True):\n",
        "    \n",
        "    try: \n",
        "      # If the assigned tags list is longer than the assigned tags list, it removes the end of the assigned tags list\n",
        "      while len(extracted) < len(assigned):\n",
        "          assigned.pop()\n",
        "      \n",
        "      precision = (\n",
        "          partial_precision_k(assigned, extracted, k)\n",
        "          if partial else precision_k(assigned, extracted, k)\n",
        "      )\n",
        "      recall = (\n",
        "          partial_recall_k(assigned, extracted, k)\n",
        "          if partial else recall_k(assigned, extracted, k)\n",
        "      )\n",
        "      return (\n",
        "          2 * precision * recall / (precision + recall)\n",
        "          if not precision == recall == 0.0 else 0.0\n",
        "      )\n",
        "    except:\n",
        "      return 0.0"
      ],
      "id": "f81ddf65"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce118a01"
      },
      "source": [
        "# Stemming\n",
        "Function which applies stemming to a lowercase version of each string of the list, which has all punctuation removed.\n",
        "\n",
        "**Source:** https://pypi.org/project/snowballstemmer/"
      ],
      "id": "ce118a01"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d5955ec"
      },
      "outputs": [],
      "source": [
        "stemmers = {'german': SnowballStemmer('german')}\n",
        "\n",
        "def preprocess(lis, language = 'german'):\n",
        "    try:\n",
        "      return list(map(stemmers[language].stem, \n",
        "            map(lambda s: s.translate(str.maketrans('', '', punctuation)),\n",
        "            map(str.lower, lis))))\n",
        "    except:\n",
        "      return lis"
      ],
      "id": "9d5955ec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx5WggVJyOwD"
      },
      "source": [
        "# Hyperparameter Tuning "
      ],
      "id": "Dx5WggVJyOwD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoSECtOlBBPs"
      },
      "source": [
        "### TF IDF\n",
        "\n",
        "**Parameters to tune:**\n",
        "*   ngram_range: Number of terms per keyphrase (default = (1, 2))\n",
        "\n",
        "**Top hyperparameters:**\n",
        "*   ngram_range: (1, 2)\n"
      ],
      "id": "IoSECtOlBBPs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOiX_3mLmM1T"
      },
      "outputs": [],
      "source": [
        "# list of hyperparameters for tuning\n",
        "params = {\n",
        "    'top_n': [10],\n",
        "    'ngram_range': [(1, 1), (1, 2), (1, 3)]}\n",
        "keys, values = zip(*params.items())\n",
        "parameter_list = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "tfidf_vectorizer_vectors, tfidf_vectorizer, tfidf_vectorizer_feature_names = tfidf_matrix(tune_df, ngram_range = (1,2))\n",
        "\n",
        "# runs the algorithm and creates a new column with the extracted keywords. Then The score is caculated in a seperate column\n",
        "# it also measures the time the algorithm takes to process the dataset\n",
        "# the dataframe with the extracted keywords is saved and the function return the mean f1 score, the used parameters, the length of the df and the time\n",
        "def tfidf_tuning(parameter_list, \n",
        "                 df, \n",
        "                 tfidf_vectorizer_vectors=tfidf_vectorizer_vectors, \n",
        "                 tfidf_vectorizer=tfidf_vectorizer, \n",
        "                 tfidf_vectorizer_feature_names=tfidf_vectorizer_feature_names):\n",
        "\n",
        "    tic = time.perf_counter()\n",
        "    df['extracted'] = df.progress_apply(lambda x: extract_per_row(x.name, tfidf_vectorizer_vectors, tfidf_vectorizer, tfidf_vectorizer_feature_names), axis=1)\n",
        "    df['f_score'] = df.apply(bulk_evaluate, axis=1)\n",
        "    \n",
        "    time_loop = time.perf_counter() - tic\n",
        "    df.to_excel('hyperparameter_tuning/extracted_keywords/tfidf_keywords.xlsx')\n",
        "    return df['f_score'].mean(), parameter_list, len(df), time_loop \n",
        "\n",
        "def extract_per_row(number_text, tfidf_vectorizer_vectors, tfidf_vectorizer, tfidf_vectorizer_feature_names, parameter_list = parameter_list):\n",
        "    keywords = tfidfvectorizer(number_text = number_text, \n",
        "                                tfidf_vectorizer_vectors = tfidf_vectorizer_vectors, \n",
        "                                tfidf_vectorizer = tfidf_vectorizer,\n",
        "                                tfidf_vectorizer_feature_names = tfidf_vectorizer_feature_names)\n",
        "    print(keywords)\n",
        "    display.clear_output(wait=True)\n",
        "    return keywords\n",
        "\n",
        "# Function to evaluate the extracted keywords which returns the f1 score\n",
        "def bulk_evaluate(row, top_n = 10):\n",
        "    actual_tags_processed = preprocess(row['keywords'], 'german')\n",
        "    predicted_tags_processed = preprocess(row['extracted'], 'german')\n",
        "    f_score = f1_measure_k(assigned = actual_tags_processed, extracted = predicted_tags_processed, k = top_n, partial = False)\n",
        "    return f_score\n",
        "\n",
        "\n",
        "def run_tuning(parameter_list):\n",
        "    # This part runs the method as a multiprocessing task to speed up the keyword extraction process\n",
        "    with ProcessPoolExecutor(max_workers=1) as executor:\n",
        "        results = [executor.submit(tfidf_tuning, parameters, test_df) for parameters in parameter_list]\n",
        "\n",
        "    results_list = []\n",
        "    for f in concurrent.futures.as_completed(results):\n",
        "        results_list.append(f.result())\n",
        "    return results_list\n",
        "\n",
        "# returns a excel with the results\n",
        "results_list = [tfidf_tuning(parameter_list[0], tune_df)]\n",
        "df = pd.DataFrame(results_list)\n",
        "df.to_excel('hyperparameter_tuning/final_run/tfidf_results.xlsx')"
      ],
      "id": "XOiX_3mLmM1T"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNWmrxBKZ0bQ"
      },
      "source": [
        "### YAKE\n",
        "\n",
        "**Parameters to tune:**\n",
        "\n",
        "*   **n: (max_ngram_size)** Maximum number of words per keyword (default = 3)\n",
        "*   **dedupLim:** (deduplication_thresold) Threshold for the value of the similarity measure for deduplication (default = 0.9)\n",
        "*   **deduplication:** Algorithm to measure the similarity of candidate keywords: levs, jaro or seqm (default = seqm)\n",
        "*   **windowsSize:** Distance (in number of tokens) considered when computing co-occurrences of tokens (default = 1)\n",
        "\n",
        "\n",
        "**Top hyperparameters:** \n",
        "*   **n:** 1\n",
        "*   **dedupLim:** 0.8\n",
        "*   **dedupFunc:** 'leve'\n",
        "*   **windowsSize:** 3\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "ZNWmrxBKZ0bQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFdRkF2HrLIp"
      },
      "outputs": [],
      "source": [
        "# list of hyperparameters for tuning\n",
        "params = {\n",
        "    'top_n': [10],\n",
        "    'n': [1, 2],\n",
        "    'dedupLim': [0.8, 0.9],\n",
        "    'dedupFunc': ['leve', 'jaro', 'seqm'],\n",
        "    'windowsSize': [1, 2, 3, 4, 5]}\n",
        "keys, values = zip(*params.items())\n",
        "parameter_list = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "# runs the algorithm and creates a new column with the extracted keywords. Then The score is caculated in a seperate column\n",
        "# it also measures the time the algorithm takes to process the dataset\n",
        "# the dataframe with the extracted keywords is saved and the function return the mean f1 score, the used parameters, the length of the df and the time\n",
        "def yake_tuning(parameter_list, df):\n",
        "    def extract_per_row(text, parameter_list = parameter_list):\n",
        "        keywords = yake(text, \n",
        "                        top_n = parameter_list[\"top_n\"], \n",
        "                        n = parameter_list[\"n\"], \n",
        "                        dedupLim = parameter_list[\"dedupLim\"], \n",
        "                        dedupFunc = parameter_list[\"dedupFunc\"], \n",
        "                        windowsSize = parameter_list[\"windowsSize\"])\n",
        "        \n",
        "        return keywords\n",
        "\n",
        "    # Function to evaluate the extracted keywords which returns the f1 score\n",
        "    def bulk_evaluate(row, top_n = 10):\n",
        "        actual_tags_processed = preprocess(row['keywords'], 'german')\n",
        "        predicted_tags_processed = preprocess(row['extracted'], 'german')\n",
        "        f_score = f1_measure_k(assigned = actual_tags_processed, extracted = predicted_tags_processed, k = top_n, partial = False)\n",
        "        \n",
        "        return f_score\n",
        "\n",
        "    tic = time.perf_counter()\n",
        "    df['extracted'] = df['text'].progress_apply(lambda x: extract_per_row(text = x))\n",
        "    df['f_score'] = df.apply(bulk_evaluate, axis=1)\n",
        "    time_loop = time.perf_counter() - tic\n",
        "    df.to_excel('/content/drive/MyDrive/Bachelorarbeit/hyperparameter_tuning/extracted_keywords/yake_keywords.xlsx')\n",
        "\n",
        "    return df['f_score'].mean(), parameter_list, len(df), time_loop \n",
        "\n",
        "def run_tuning(parameter_list, df):\n",
        "    # This part runs the method as a multiprocessing task to speed up the keyword extraction process\n",
        "    with ProcessPoolExecutor(max_workers=30) as executor:\n",
        "        results = [executor.submit(yake_tuning, parameters, df) for parameters in parameter_list]\n",
        "\n",
        "    results_list = []\n",
        "    for f in concurrent.futures.as_completed(results):\n",
        "        results_list.append(f.result())\n",
        "\n",
        "    return results_list\n",
        "\n",
        "# returns a excel with the results\n",
        "results_list = run_tuning(parameter_list, tune_df)\n",
        "df = pd.DataFrame(results_list)\n",
        "df.to_excel('/content/drive/MyDrive/Bachelorarbeit/hyperparameter_tuning/final_run/yake_results.xlsx')"
      ],
      "id": "AFdRkF2HrLIp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm5PSAJfsfa0"
      },
      "source": [
        "### RAKE\n",
        "\n",
        "**Parameters to tune:**\n",
        "\n",
        "*    **minCharacters:** Minimum characters allowed in a keyword (default = 1)\n",
        "*    **maxWords:** Maximum number of words allowed in a phrase considered as a keyword (default = 5)\n",
        "*    **minFrequency:** Minimum number of occurrences of a keyword in the text to be considered as a keyword (default = 1)\n",
        "\n",
        "**Top hyperparameters:** \n",
        "\n",
        "*   **minCharacters:** 2\n",
        "*   **maxWords:** 1\n",
        "*   **minFrequency:** 1"
      ],
      "id": "gm5PSAJfsfa0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jHjnAGrSKsO"
      },
      "outputs": [],
      "source": [
        "# list of hyperparameters for tuning\n",
        "params = {\n",
        "    'top_n': [10],\n",
        "    'minCharacters': [1, 2, 4],\n",
        "    'maxWords': [2, 3, 5],\n",
        "    'minFrequency': [1, 2, 3]}\n",
        "keys, values = zip(*params.items())\n",
        "parameter_list = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "# runs the algorithm and creates a new column with the extracted keywords. Then The score is caculated in a seperate column\n",
        "# it also measures the time the algorithm takes to process the dataset\n",
        "# the dataframe with the extracted keywords is saved and the function return the mean f1 score, the used parameters, the length of the df and the time\n",
        "def rake_tuning(parameter_list, df):\n",
        "    def extract_per_row(text, parameter_list = parameter_list):\n",
        "        keywords = rake(text, \n",
        "                        minCharacters = parameter_list[\"minCharacters\"], \n",
        "                        maxWords = parameter_list[\"maxWords\"], \n",
        "                        minFrequency= parameter_list[\"minFrequency\"])\n",
        "        \n",
        "        return keywords\n",
        "\n",
        "    # Function to evaluate the extracted keywords which returns the f1 score\n",
        "    def bulk_evaluate(row, top_n = 10):\n",
        "        actual_tags_processed = preprocess(row['keywords'], 'german')\n",
        "        predicted_tags_processed = preprocess(row['extracted'], 'german')\n",
        "        f_score = f1_measure_k(assigned = actual_tags_processed, extracted = predicted_tags_processed, k = top_n, partial = False)\n",
        "        return f_score\n",
        "\n",
        "    tic = time.perf_counter()\n",
        "    df['extracted'] = df['text'].progress_apply(lambda x: extract_per_row(text = x))\n",
        "    df['f_score'] = df.apply(bulk_evaluate, axis=1)\n",
        "    time_loop = time.perf_counter() - tic\n",
        "    df.to_excel('/content/drive/MyDrive/Bachelorarbeit/hyperparameter_tuning/extracted_keywords/rake_keywords.xlsx')\n",
        "\n",
        "    return df['f_score'].mean(), parameter_list, len(df), time_loop \n",
        "\n",
        "def run_tuning(parameter_list, df):\n",
        "    # This part runs the method as a multiprocessing task to speed up the keyword extraction process\n",
        "    with ProcessPoolExecutor(max_workers=30) as executor:\n",
        "        results = [executor.submit(rake_tuning, parameters, df) for parameters in parameter_list]\n",
        "\n",
        "    results_list = []\n",
        "    for f in concurrent.futures.as_completed(results):\n",
        "        results_list.append(f.result())\n",
        "\n",
        "    return results_list\n",
        "\n",
        "# returns a excel with the results\n",
        "results_list = run_tuning(parameter_list, tune_df)\n",
        "df = pd.DataFrame(results_list)\n",
        "df.to_excel('/content/drive/MyDrive/Bachelorarbeit/hyperparameter_tuning/final_run/rake_results.xlsx')"
      ],
      "id": "2jHjnAGrSKsO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdVcwJ7iT_M7"
      },
      "source": [
        "### TextRank\n",
        "\n",
        "**Parameters to tune:**\n",
        "\n",
        "*   **window:** Window for connecting two words in the graph (default = 2)\n",
        "*   **pos:** Set of valid pos for words to be considered as a node in the graph (default = {'NOUN’ ’PROPN'  'ADJ'})\n",
        "\n",
        "*   **top_percent:** Percentage of top vertices to keep for phrase generation (default = 0.33)\n",
        "\n",
        "**Top hyperparameters:** \n",
        "*   **window:** 2\n",
        "*   **pos:** {'NOUN', 'PROPN'}\n",
        "*   **top_percent:** 0.33"
      ],
      "id": "DdVcwJ7iT_M7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyCQOvqmV4nJ"
      },
      "outputs": [],
      "source": [
        "# list of hyperparameters for tuning\n",
        "params = {\n",
        "    'top_n': [10],\n",
        "    'window': [2, 3, 5],\n",
        "    'pos': [{'NOUN', 'PROPN'}, {'NOUN', 'PROPN', 'ADJ'}],\n",
        "    'top_percent': [0.1, 0.3, 0.5]}\n",
        "keys, values = zip(*params.items())\n",
        "parameter_list = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "def extract_all(df):\n",
        "    list_texts = df['text'].tolist()\n",
        "    list_index = list(df.index.values)\n",
        "    keyword_list = []\n",
        "    # This part runs the method as a multiprocessing task to speed up the keyword extraction process\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        for arg, res in zip(list_index, executor.map(extract_per_row, list_texts, chunksize = 4)):\n",
        "            print(len(keyword_list), res)\n",
        "            display.clear_output(wait=True)\n",
        "            keyword_list.append(res)\n",
        "    df['extracted'] = keyword_list\n",
        "    return df\n",
        "\n",
        "\n",
        "def extract_per_row(text, parameter_list = parameter_list[0]):\n",
        "    keywords = textrank(text, \n",
        "                        top_n = parameter_list['top_n'], \n",
        "                        window = parameter_list['window'], \n",
        "                        pos = parameter_list['pos'], \n",
        "                        top_percent = parameter_list['top_percent'],)\n",
        "\n",
        "    return keywords\n",
        "\n",
        "# Function to evaluate the extracted keywords which returns the f1 score\n",
        "def bulk_evaluate(row, top_n = 10):\n",
        "    actual_tags_processed = preprocess(row['keywords'], 'german')\n",
        "    predicted_tags_processed = preprocess(row['extracted'], 'german')\n",
        "    f_score = f1_measure_k(assigned = actual_tags_processed, extracted = predicted_tags_processed, k = top_n, partial = False)\n",
        "    return f_score\n",
        "\n",
        "# runs the algorithm and creates a new column with the extracted keywords. Then The score is caculated in a seperate column\n",
        "# it also measures the time the algorithm takes to process the dataset\n",
        "# the dataframe with the extracted keywords is saved and the function return the mean f1 score, the used parameters, the length of the df and the time\n",
        "def evaluate_textrank(df):\n",
        "    tic = time.perf_counter()\n",
        "    df = extract_all(df)\n",
        "    df['f_score'] = df.apply(bulk_evaluate, axis=1)\n",
        "    time_loop = time.perf_counter() - tic\n",
        "    \n",
        "    df.to_excel('/content/drive/MyDrive/Bachelorarbeit/hyperparameter_tuning/extracted_keywords/textrank_keywords.xlsx')\n",
        "    return df['f_score'].mean(), parameter_list, len(df), time_loop \n",
        "\n",
        "# returns a excel with the results\n",
        "results = evaluate_textrank(tune_df)\n",
        "df = pd.DataFrame([results])\n",
        "df.to_excel('/content/drive/MyDrive/Bachelorarbeit/hyperparameter_tuning/final_run/textrank_results.xlsx')"
      ],
      "id": "AyCQOvqmV4nJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUhbJiQfiWYL"
      },
      "source": [
        "### SingleRank \n",
        "\n",
        "**Parameters to tune:**\n",
        "\n",
        "*   **window:** Window within the sentence for connecting words in the graph (default = 10)\n",
        "*   **redundancy_removal:** Boolean variable whether redundant keyphrases are filtered out from the n-best list using levenshtein distance (default = True)\n",
        "*   **pos:** Set of valid pos for words to be considered as nodes in the graph (default = 'NOUN’ ’PROPN'  'ADJ')\n",
        "\n",
        "**Top hyperparameter:** \n",
        "*   **window:** 12 \n",
        "*   **redundancy_removal:** True\n",
        "*   **pos:** {'NOUN', 'ADJ', 'PROPN'}\n"
      ],
      "id": "WUhbJiQfiWYL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLctxaCLTN_m"
      },
      "outputs": [],
      "source": [
        "# list of hyperparameters for tuning\n",
        "params = {\n",
        "    'top_n': [10],\n",
        "    'window': [8, 10, 12],\n",
        "    'normalized': [False],\n",
        "    'redundancy_removal': [True, False],\n",
        "    'pos': [{'NOUN', 'PROPN', 'ADJ'}]}\n",
        "keys, values = zip(*params.items())\n",
        "parameter_list = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "def extract_all(df):\n",
        "    list_texts = df['text'].tolist()\n",
        "    list_index = list(df.index.values)\n",
        "    keyword_list = []\n",
        "    # This part runs the method as a multiprocessing task to speed up the keyword extraction process\n",
        "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
        "        for arg, res in zip(list_index, executor.map(extract_per_row, list_texts, chunksize = 3)):\n",
        "            print(len(keyword_list), res)\n",
        "            display.clear_output(wait=True)\n",
        "            keyword_list.append(res)\n",
        "    df['extracted'] = keyword_list\n",
        "    return df\n",
        "\n",
        "\n",
        "def extract_per_row(text, parameter_list = parameter_list[0]):\n",
        "    keywords = singlerank(text, \n",
        "                    top_n = parameter_list[\"top_n\"], \n",
        "                    window = parameter_list[\"window\"], \n",
        "                    normalized = parameter_list[\"normalized\"], \n",
        "                    redundancy_removal = parameter_list[\"redundancy_removal\"], \n",
        "                    pos = parameter_list[\"pos\"])\n",
        "    #print(keywords)\n",
        "    #display.clear_output(wait=True)\n",
        "    return keywords\n",
        "\n",
        "# Function to evaluate the extracted keywords which returns the f1 score\n",
        "def bulk_evaluate(row, top_n = 10):\n",
        "    actual_tags_processed = preprocess(row['keywords'], 'german')\n",
        "    predicted_tags_processed = preprocess(row['extracted'], 'german')\n",
        "    f_score = f1_measure_k(assigned = actual_tags_processed, extracted = predicted_tags_processed, k = top_n, partial = False)\n",
        "    return f_score\n",
        "\n",
        "# runs the algorithm and creates a new column with the extracted keywords. Then The score is caculated in a seperate column\n",
        "# it also measures the time the algorithm takes to process the dataset\n",
        "# the dataframe with the extracted keywords is saved and the function return the mean f1 score, the used parameters, the length of the df and the time\n",
        "def evaluate_singlerank(df):\n",
        "    tic = time.perf_counter()\n",
        "    df = extract_all(df)\n",
        "    df['f_score'] = df.apply(bulk_evaluate, axis=1)\n",
        "    time_loop = time.perf_counter() - tic\n",
        "    \n",
        "    df.to_excel('/content/drive/MyDrive/Bachelorarbeit/hyperparameter_tuning/extracted_keywords/singlerank_keywords.xlsx')\n",
        "    return df['f_score'].mean(), parameter_list, len(df), time_loop \n",
        "\n",
        "# returns a excel with the results\n",
        "results = evaluate_singlerank(tune_df)\n",
        "df = pd.DataFrame([results])\n",
        "df.to_excel('/content/drive/MyDrive/Bachelorarbeit/hyperparameter_tuning/final_run/singlerank_results.xlsx')"
      ],
      "id": "tLctxaCLTN_m"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AulkzvenwMH9"
      },
      "source": [
        "### KeyBert\n",
        "\n",
        "**Parameters to tune:**\n",
        "\n",
        "*   **keyphrase_ngram_range:** Minimum and maximum number of words per keyphrase (default = (1, 1))\n",
        "*   **min_df:** Minimum frequency of words (default = 1)\n",
        "*   **model:** BERT model (default = all-MiniLM-L6-v2)\n",
        "\n",
        "**Top hyperparameters:**\n",
        "\n",
        "*   **keyphrase_ngram_range:** (1, 1)\n",
        "*   **min_df:** 1\n",
        "*   **model:** paraphrase-multilingual-MiniLM-L12-v2"
      ],
      "id": "AulkzvenwMH9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mSvlI1WfSHxk"
      },
      "outputs": [],
      "source": [
        "# list of hyperparameters for tuning\n",
        "keybert_params = {\n",
        "    'keyphrase_ngram_range': [(1, 2)],\n",
        "    'top_n': [10],\n",
        "    'min_df': [1, 2, 3],\n",
        "    'model': ['kw_model_2', 'kw_model_3', 'kw_model_5', 'kw_model_6', 'kw_model_8'],\n",
        "    'vectorizer': [vectorizer_keybert]}\n",
        "keys, values = zip(*keybert_params.items())\n",
        "parameter_list = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "def keybert_bulk_tuning(parameters, df):\n",
        "    keyphrase_ngram_range = parameters[\"keyphrase_ngram_range\"]\n",
        "    top_n = parameters[\"top_n\"]\n",
        "    min_df = parameters[\"min_df\"]\n",
        "    # Take the model name as string and find the corresponding global KeyBERT object\n",
        "    model = getattr(sys.modules[__name__], parameters[\"model\"])\n",
        "    vectorizer = parameters[\"vectorizer\"]\n",
        "\n",
        "    return keybert_bulk(df, keyphrase_ngram_range, top_n, min_df, vectorizer, model)\n",
        "\n",
        "# Function to evaluate the extracted keywords which returns the f1 score\n",
        "def keybert_bulk_evaluate(row, top_n = 10):\n",
        "    actual_tags_processed = preprocess(row['keywords'], 'german')\n",
        "    predicted_tags_processed = preprocess(row['extracted'], 'german')\n",
        "    f_score = f1_measure_k(assigned = actual_tags_processed, extracted = predicted_tags_processed, k = top_n, partial = True)\n",
        "\n",
        "    return f_score\n",
        "\n",
        "# runs the algorithm and creates a new column with the extracted keywords. Then The score is caculated in a seperate column\n",
        "# it also measures the time the algorithm takes to process the dataset\n",
        "# the dataframe with the extracted keywords is saved and the function return the mean f1 score, the used parameters, the length of the df and the time\n",
        "def keybert_bulk_run(parameters, df):\n",
        "    print('Started to extract keywords for ', str(parameters['model']), str(parameters['vectorizer']))\n",
        "    tic = time.perf_counter()\n",
        "    df_extracted = keybert_bulk_tuning(parameters, df)\n",
        "    df_extracted['f_score'] = df_extracted.apply(keybert_bulk_evaluate, axis=1)\n",
        "    time_loop = time.perf_counter() - tic\n",
        "    path = '/content/drive/MyDrive/Bachelorarbeit/hyperparameter_tuning/extracted_keywords/keybert_keywords.xlsx'\n",
        "    df_extracted.to_excel(path)\n",
        "\n",
        "    return df_extracted[\"f_score\"].mean(), parameters, len(df), time_loop\n",
        "\n",
        "def keybert_bulk_multi(df, parameter_list):\n",
        "    # This part runs the method as a multiprocessing task to speed up the keyword extraction process\n",
        "    with ThreadPoolExecutor(max_workers = 8) as executor:\n",
        "        results = [executor.submit(keybert_bulk_run, parameters, df) for parameters in parameter_list]\n",
        "   \n",
        "    results_list = []\n",
        "    for f in concurrent.futures.as_completed(results):\n",
        "        results_list.append(f.result(), )\n",
        "\n",
        "    return results_list\n",
        "\n",
        "# returns a excel with the results\n",
        "results_list = keybert_bulk_multi(tune_df, parameter_list)\n",
        "df_keybert = pd.DataFrame(results_list)\n",
        "df_keybert.to_excel('/content/drive/MyDrive/Bachelorarbeit/hyperparameter_tuning/final_run/keybert_results.xlsx')"
      ],
      "id": "mSvlI1WfSHxk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Run"
      ],
      "metadata": {
        "id": "hOOTPg0RBTzf"
      },
      "id": "hOOTPg0RBTzf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF\n",
        "\n",
        "**Top hyperparameters:**\n",
        "*   ngram_range: (1, 2)"
      ],
      "metadata": {
        "id": "NtNJmxNyIj3o"
      },
      "id": "NtNJmxNyIj3o"
    },
    {
      "cell_type": "code",
      "source": [
        "# top hyperparameters after tuning\n",
        "params = {\n",
        "    'top_n': [10],\n",
        "    'ngram_range': [(1, 2)]}\n",
        "\n",
        "keys, values = zip(*params.items())\n",
        "parameter_list = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "tfidf_vectorizer_vectors, tfidf_vectorizer, tfidf_vectorizer_feature_names = tfidf_matrix(tune_df, ngram_range = (1,2))\n",
        "\n",
        "def tfidf_tuning(parameter_list, \n",
        "                 df, \n",
        "                 tfidf_vectorizer_vectors=tfidf_vectorizer_vectors, \n",
        "                 tfidf_vectorizer=tfidf_vectorizer, \n",
        "                 tfidf_vectorizer_feature_names=tfidf_vectorizer_feature_names):\n",
        "\n",
        "    tic = time.perf_counter()\n",
        "    df['extracted'] = df.progress_apply(lambda x: extract_per_row(x.name, tfidf_vectorizer_vectors, tfidf_vectorizer, tfidf_vectorizer_feature_names), axis=1)\n",
        "    df['f_score'] = df.apply(bulk_evaluate, axis=1)\n",
        "    \n",
        "    time_loop = time.perf_counter() - tic\n",
        "    df.to_excel('hyperparameter_tuning/extracted_keywords/tfidf_keywords.xlsx')\n",
        "    return df['f_score'].mean(), parameter_list, len(df), time_loop \n",
        "\n",
        "def extract_per_row(number_text, tfidf_vectorizer_vectors, tfidf_vectorizer, tfidf_vectorizer_feature_names, parameter_list = parameter_list):\n",
        "    keywords = tfidfvectorizer(number_text = number_text, \n",
        "                                tfidf_vectorizer_vectors = tfidf_vectorizer_vectors, \n",
        "                                tfidf_vectorizer = tfidf_vectorizer,\n",
        "                                tfidf_vectorizer_feature_names = tfidf_vectorizer_feature_names)\n",
        "    print(keywords)\n",
        "    display.clear_output(wait=True)\n",
        "    return keywords\n",
        "\n",
        "# Function to evaluate the extracted keywords which returns the f1 score\n",
        "def bulk_evaluate(row, top_n = 10):\n",
        "    actual_tags_processed = preprocess(row['keywords'], 'german')\n",
        "    predicted_tags_processed = preprocess(row['extracted'], 'german')\n",
        "    f_score = f1_measure_k(assigned = actual_tags_processed, extracted = predicted_tags_processed, k = top_n, partial = False)\n",
        "    return f_score\n",
        "\n",
        "def run_tuning(parameter_list):\n",
        "    # This part runs the method as a multiprocessing task to speed up the keyword extraction process\n",
        "    with ProcessPoolExecutor(max_workers=1) as executor:\n",
        "        results = [executor.submit(tfidf_tuning, parameters, test_df) for parameters in parameter_list]\n",
        "\n",
        "    results_list = []\n",
        "    for f in concurrent.futures.as_completed(results):\n",
        "        results_list.append(f.result())\n",
        "    return results_list\n",
        "\n",
        "# returns a excel with the results\n",
        "results_list = [tfidf_tuning(parameter_list[0], test_df)]\n",
        "df = pd.DataFrame(results_list)\n",
        "df.to_excel('hyperparameter_tuning/final_run/tfidf_results.xlsx')"
      ],
      "metadata": {
        "id": "oe6hhiIsIjjn"
      },
      "id": "oe6hhiIsIjjn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YAKE\n",
        "\n",
        "**Top hyperparameters:** \n",
        "*   **n:** 1\n",
        "*   **dedupLim:** 0.8\n",
        "*   **dedupFunc:** 'leve'\n",
        "*   **windowsSize:** 3"
      ],
      "metadata": {
        "id": "n4cGU6rsE-K6"
      },
      "id": "n4cGU6rsE-K6"
    },
    {
      "cell_type": "code",
      "source": [
        "# top hyperparameters after tuning\n",
        "params = {\n",
        "    'top_n': [10],\n",
        "    'n': [1],\n",
        "    'dedupLim': [0.8],\n",
        "    'dedupFunc': ['leve'],\n",
        "    'windowsSize': [3]}\n",
        "keys, values = zip(*params.items())\n",
        "parameter_list = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "def yake_tuning(parameter_list, df):\n",
        "    def extract_per_row(text, parameter_list = parameter_list):\n",
        "        keywords = yake(text, \n",
        "                        top_n = parameter_list[\"top_n\"], \n",
        "                        n = parameter_list[\"n\"], \n",
        "                        dedupLim = parameter_list[\"dedupLim\"], \n",
        "                        dedupFunc = parameter_list[\"dedupFunc\"], \n",
        "                        windowsSize = parameter_list[\"windowsSize\"])\n",
        "\n",
        "        return keywords\n",
        "\n",
        "    # Function to evaluate the extracted keywords which returns the f1 score\n",
        "    def bulk_evaluate(row, top_n = 10):\n",
        "        actual_tags_processed = preprocess(row['keywords'], 'german')\n",
        "        predicted_tags_processed = preprocess(row['extracted'], 'german')\n",
        "        f_score = f1_measure_k(assigned = actual_tags_processed, extracted = predicted_tags_processed, k = top_n, partial = False)\n",
        "        return f_score\n",
        "\n",
        "    tic = time.perf_counter()\n",
        "    df['extracted'] = df['text'].progress_apply(lambda x: extract_per_row(text = x))\n",
        "    df['f_score'] = df.apply(bulk_evaluate, axis=1)\n",
        "    time_loop = time.perf_counter() - tic\n",
        "    df.to_excel('/content/drive/MyDrive/Bachelorarbeit/extracted_keywords/yake_keywords.xlsx')\n",
        "\n",
        "    return df['f_score'].mean(), parameter_list, len(df), time_loop \n",
        "\n",
        "def run_tuning(parameter_list, df):\n",
        "    # This part runs the method as a multiprocessing task to speed up the keyword extraction process\n",
        "    with ProcessPoolExecutor(max_workers=30) as executor:\n",
        "        results = [executor.submit(yake_tuning, parameters, df) for parameters in parameter_list]\n",
        "\n",
        "    results_list = []\n",
        "    for f in concurrent.futures.as_completed(results):\n",
        "        results_list.append(f.result())\n",
        "\n",
        "    return results_list\n",
        "\n",
        "# returns a excel with the results\n",
        "results_list = run_tuning(parameter_list, test_df)\n",
        "df = pd.DataFrame(results_list)\n",
        "df.to_excel('/content/drive/MyDrive/Bachelorarbeit/final_run/yake_results.xlsx')"
      ],
      "metadata": {
        "id": "mLQPFhmYBVfJ"
      },
      "id": "mLQPFhmYBVfJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAKE\n",
        "\n",
        "**Top hyperparameters:** \n",
        "\n",
        "*   **minCharacters:** 2\n",
        "*   **maxWords:** 1\n",
        "*   **minFrequency:** 1"
      ],
      "metadata": {
        "id": "jY5DWV59FMOa"
      },
      "id": "jY5DWV59FMOa"
    },
    {
      "cell_type": "code",
      "source": [
        "# top hyperparameters after tuning\n",
        "params = {\n",
        "    'top_n': [10],\n",
        "    'minCharacters': [2],\n",
        "    'maxWords': [1],\n",
        "    'minFrequency': [1]}\n",
        "keys, values = zip(*params.items())\n",
        "parameter_list = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "def rake_tuning(parameter_list, df):\n",
        "    def extract_per_row(text, parameter_list = parameter_list):\n",
        "        keywords = rake(text, \n",
        "                        minCharacters = parameter_list[\"minCharacters\"], \n",
        "                        maxWords = parameter_list[\"maxWords\"], \n",
        "                        minFrequency= parameter_list[\"minFrequency\"])\n",
        "\n",
        "        return keywords\n",
        "\n",
        "    # Function to evaluate the extracted keywords which returns the f1 score\n",
        "    def bulk_evaluate(row, top_n = 10):\n",
        "        actual_tags_processed = preprocess(row['keywords'], 'german')\n",
        "        predicted_tags_processed = preprocess(row['extracted'], 'german')\n",
        "        f_score = f1_measure_k(assigned = actual_tags_processed, extracted = predicted_tags_processed, k = top_n, partial = False)\n",
        "        return f_score\n",
        "\n",
        "    tic = time.perf_counter()\n",
        "    df['extracted'] = df['text'].progress_apply(lambda x: extract_per_row(text = x))\n",
        "    df['f_score'] = df.apply(bulk_evaluate, axis=1)\n",
        "    time_loop = time.perf_counter() - tic\n",
        "    df.to_excel('/content/drive/MyDrive/Bachelorarbeit/extracted_keywords/rake_keywords.xlsx')\n",
        "\n",
        "    return df['f_score'].mean(), parameter_list, len(df), time_loop \n",
        "\n",
        "def run_tuning(parameter_list, df):\n",
        "    # This part runs the method as a multiprocessing task to speed up the keyword extraction process\n",
        "    with ProcessPoolExecutor(max_workers=30) as executor:\n",
        "        results = [executor.submit(rake_tuning, parameters, df) for parameters in parameter_list]\n",
        "\n",
        "    results_list = []\n",
        "    for f in concurrent.futures.as_completed(results):\n",
        "        results_list.append(f.result())\n",
        "\n",
        "    return results_list\n",
        "\n",
        "# returns a excel with the results\n",
        "results_list = run_tuning(parameter_list, test_df)\n",
        "df = pd.DataFrame(results_list)\n",
        "df.to_excel('/content/drive/MyDrive/Bachelorarbeit/final_run/rake_results.xlsx')"
      ],
      "metadata": {
        "id": "80-W_nf6FM5Y"
      },
      "id": "80-W_nf6FM5Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TextRank\n",
        "\n",
        "**Top hyperparameters:** \n",
        "*   **window:** 2\n",
        "*   **pos:** {'NOUN', 'PROPN'}\n",
        "*   **top_percent:** 0.33"
      ],
      "metadata": {
        "id": "BGdxfarrFoji"
      },
      "id": "BGdxfarrFoji"
    },
    {
      "cell_type": "code",
      "source": [
        "# top hyperparameters after tuning\n",
        "params = {\n",
        "    'top_n': [10],\n",
        "    'window': [2],\n",
        "    'pos': [{'NOUN', 'PROPN'}],\n",
        "    'top_percent': [0.33]}\n",
        "keys, values = zip(*params.items())\n",
        "parameter_list = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "def extract_all(df):\n",
        "    list_texts = df['text'].tolist()\n",
        "    list_index = list(df.index.values)\n",
        "    keyword_list = []\n",
        "    # This part runs the method as a multiprocessing task to speed up the keyword extraction process\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        for arg, res in zip(list_index, executor.map(extract_per_row, list_texts, chunksize = 4)):\n",
        "            print(len(keyword_list), res)\n",
        "            display.clear_output(wait=True)\n",
        "            keyword_list.append(res)\n",
        "    df['extracted'] = keyword_list\n",
        "    return df\n",
        "\n",
        "\n",
        "def extract_per_row(text, parameter_list = parameter_list[0]):\n",
        "    keywords = textrank(text, \n",
        "                        top_n = parameter_list['top_n'], \n",
        "                        window = parameter_list['window'], \n",
        "                        pos = parameter_list['pos'], \n",
        "                        top_percent = parameter_list['top_percent'],)\n",
        "\n",
        "    return keywords\n",
        "\n",
        "# Function to evaluate the extracted keywords which returns the f1 score\n",
        "def bulk_evaluate(row, top_n = 10):\n",
        "    actual_tags_processed = preprocess(row['keywords'], 'german')\n",
        "    predicted_tags_processed = preprocess(row['extracted'], 'german')\n",
        "    f_score = f1_measure_k(assigned = actual_tags_processed, extracted = predicted_tags_processed, k = top_n, partial = False)\n",
        "    return f_score\n",
        "\n",
        "\n",
        "def evaluate_textrank(df):\n",
        "    tic = time.perf_counter()\n",
        "    df = extract_all(df)\n",
        "    df['f_score'] = df.apply(bulk_evaluate, axis=1)\n",
        "    time_loop = time.perf_counter() - tic\n",
        "    \n",
        "    df.to_excel('/content/drive/MyDrive/Bachelorarbeit/extracted_keywords/textrank_keywords.xlsx')\n",
        "    return df['f_score'].mean(), parameter_list, len(df), time_loop \n",
        "\n",
        "# returns a excel with the results\n",
        "results = evaluate_textrank(test_df)\n",
        "df = pd.DataFrame([results])\n",
        "df.to_excel('/content/drive/MyDrive/Bachelorarbeit/final_run/textrank_results.xlsx')"
      ],
      "metadata": {
        "id": "D7nrdmuCFqlN"
      },
      "id": "D7nrdmuCFqlN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SingleRank\n",
        "\n",
        "**Top hyperparameter:** \n",
        "*   **window:** 12 \n",
        "*   **redundancy_removal:** True\n",
        "*   **pos:** {'NOUN', 'ADJ', 'PROPN'}"
      ],
      "metadata": {
        "id": "0amOPAucF6bi"
      },
      "id": "0amOPAucF6bi"
    },
    {
      "cell_type": "code",
      "source": [
        "# top hyperparameters after tuning\n",
        "params = {\n",
        "    'top_n': [10],\n",
        "    'window': [12],\n",
        "    'normalized': [False],\n",
        "    'redundancy_removal': [True],\n",
        "    'pos': [{'NOUN', 'PROPN', 'ADJ'}]}\n",
        "keys, values = zip(*params.items())\n",
        "parameter_list = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "def extract_all(df):\n",
        "    list_texts = df['text'].tolist()\n",
        "    list_index = list(df.index.values)\n",
        "    keyword_list = []\n",
        "    # This part runs the method as a multiprocessing task to speed up the keyword extraction process\n",
        "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
        "        for arg, res in zip(list_index, executor.map(extract_per_row, list_texts, chunksize = 3)):\n",
        "            print(len(keyword_list), res)\n",
        "            display.clear_output(wait=True)\n",
        "            keyword_list.append(res)\n",
        "    df['extracted'] = keyword_list\n",
        "    return df\n",
        "\n",
        "\n",
        "def extract_per_row(text, parameter_list = parameter_list[0]):\n",
        "    keywords = singlerank(text, \n",
        "                    top_n = parameter_list[\"top_n\"], \n",
        "                    window = parameter_list[\"window\"], \n",
        "                    normalized = parameter_list[\"normalized\"], \n",
        "                    redundancy_removal = parameter_list[\"redundancy_removal\"], \n",
        "                    pos = parameter_list[\"pos\"])\n",
        "\n",
        "    return keywords\n",
        "\n",
        "# Function to evaluate the extracted keywords which returns the f1 score\n",
        "def bulk_evaluate(row, top_n = 10):\n",
        "    actual_tags_processed = preprocess(row['keywords'], 'german')\n",
        "    predicted_tags_processed = preprocess(row['extracted'], 'german')\n",
        "    f_score = f1_measure_k(assigned = actual_tags_processed, extracted = predicted_tags_processed, k = top_n, partial = False)\n",
        "    return f_score\n",
        "\n",
        "def evaluate_singlerank(df):\n",
        "    tic = time.perf_counter()\n",
        "    df = extract_all(df)\n",
        "    df['f_score'] = df.apply(bulk_evaluate, axis=1)\n",
        "    time_loop = time.perf_counter() - tic\n",
        "    \n",
        "    df.to_excel('/content/drive/MyDrive/Bachelorarbeit/extracted_keywords/singlerank_keywords.xlsx')\n",
        "    return df['f_score'].mean(), parameter_list, len(df), time_loop \n",
        "\n",
        "# returns a excel with the results\n",
        "results = evaluate_singlerank(test_df)\n",
        "df = pd.DataFrame([results])\n",
        "df.to_excel('/content/drive/MyDrive/Bachelorarbeit/final_run/singlerank_results.xlsx')"
      ],
      "metadata": {
        "id": "KjXQIhpqF812"
      },
      "id": "KjXQIhpqF812",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KeyBERT\n",
        "\n",
        "**Top hyperparameters:**\n",
        "\n",
        "*   **keyphrase_ngram_range:** (1, 1)\n",
        "*   **min_df:** 1\n",
        "*   **model:** paraphrase-multilingual-MiniLM-L12-v2 (kw_model_8); distiluse-base-multilingual-cased-v2 (kw_model_6)\n",
        "*   **vectorizer:** KeyphraseCountVectorizer(spacy_pipeline='de_core_news_sm') (vectorizer_keybert)"
      ],
      "metadata": {
        "id": "E1aduZpfGLGw"
      },
      "id": "E1aduZpfGLGw"
    },
    {
      "cell_type": "code",
      "source": [
        "# top hyperparameters after tuning\n",
        "keybert_params = {\n",
        "    'keyphrase_ngram_range': [(1, 1)],\n",
        "    'top_n': [10],\n",
        "    'min_df': [1],\n",
        "    'model': ['kw_model_6', 'kw_model_8'], # We take the top 2 best performing language models.\n",
        "    'vectorizer': [vectorizer_keybert]}\n",
        "keys, values = zip(*keybert_params.items())\n",
        "parameter_list = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "def keybert_bulk_tuning(parameters, df):\n",
        "    keyphrase_ngram_range = parameters[\"keyphrase_ngram_range\"]\n",
        "    top_n = parameters[\"top_n\"]\n",
        "    min_df = parameters[\"min_df\"]\n",
        "    # Take the model name as string and find the corresponding global KeyBERT object\n",
        "    model = getattr(sys.modules[__name__], parameters[\"model\"])\n",
        "    vectorizer = parameters[\"vectorizer\"]\n",
        "\n",
        "    return keybert_bulk(df, keyphrase_ngram_range, top_n, min_df, vectorizer, model)\n",
        "\n",
        "# Function to evaluate the extracted keywords which returns the f1 score\n",
        "def keybert_bulk_evaluate(row, top_n = 10):\n",
        "    actual_tags_processed = preprocess(row['keywords'], 'german')\n",
        "    predicted_tags_processed = preprocess(row['extracted'], 'german')\n",
        "    f_score = f1_measure_k(assigned = actual_tags_processed, extracted = predicted_tags_processed, k = top_n, partial = True)\n",
        "\n",
        "    return f_score\n",
        "\n",
        "def keybert_bulk_run(parameters, df):\n",
        "    print('Started to extract keywords for ', str(parameters['model']), str(parameters['vectorizer']))\n",
        "    tic = time.perf_counter()\n",
        "    df_extracted = keybert_bulk_tuning(parameters, df)\n",
        "    df_extracted['f_score'] = df_extracted.apply(keybert_bulk_evaluate, axis=1)\n",
        "    time_loop = time.perf_counter() - tic\n",
        "    path = '/content/drive/MyDrive/Bachelorarbeit/extracted_keywords/keybert_keywords.xlsx'\n",
        "    df_extracted.to_excel(path)\n",
        "\n",
        "    return df_extracted[\"f_score\"].mean(), parameters, len(df), time_loop\n",
        "\n",
        "def keybert_bulk_multi(df, parameter_list):\n",
        "    # This part runs the method as a multiprocessing task to speed up the keyword extraction process\n",
        "    with ThreadPoolExecutor(max_workers = 8) as executor:\n",
        "        results = [executor.submit(keybert_bulk_run, parameters, df) for parameters in parameter_list]\n",
        "   \n",
        "    results_list = []\n",
        "    for f in concurrent.futures.as_completed(results):\n",
        "        results_list.append(f.result(), )\n",
        "\n",
        "    return results_list\n",
        "\n",
        "# returns a excel with the results\n",
        "results_list = keybert_bulk_multi(test_df, parameter_list)\n",
        "df_keybert = pd.DataFrame(results_list)\n",
        "df_keybert.to_excel('/content/drive/MyDrive/Bachelorarbeit/final_run/keybert_results.xlsx')"
      ],
      "metadata": {
        "id": "UO5Mm2olGLc5"
      },
      "id": "UO5Mm2olGLc5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "bc58efad",
        "a683cc3c",
        "2120897a",
        "4bfa37fe",
        "ee4c74e9",
        "84677cf9",
        "c514bc5d",
        "SDeYPvIU0LU6",
        "Ba7e4bPRAY6q",
        "gTxkxf9WARoQ",
        "7d656dba",
        "ce118a01",
        "IoSECtOlBBPs",
        "ZNWmrxBKZ0bQ",
        "gm5PSAJfsfa0",
        "DdVcwJ7iT_M7",
        "WUhbJiQfiWYL",
        "AulkzvenwMH9",
        "NtNJmxNyIj3o",
        "n4cGU6rsE-K6",
        "jY5DWV59FMOa",
        "BGdxfarrFoji",
        "0amOPAucF6bi",
        "E1aduZpfGLGw"
      ],
      "name": "MAIN CODE Experiment_setup.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}